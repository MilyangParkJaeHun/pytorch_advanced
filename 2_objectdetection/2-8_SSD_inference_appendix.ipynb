{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd_predict(img_index, img_list, dataset, net=None, dataconfidence_level=0.5):\n",
    "\n",
    "    image_file_path = img_list[img_index]\n",
    "    img = cv2.imread(image_file_path)  \n",
    "    height, width, channels = img.shape  \n",
    "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    im, gt = dataset.__getitem__(img_index)\n",
    "    true_bbox = gt[:, 0:4] * [width, height, width, height]\n",
    "    true_label_index = gt[:, 4].astype(int)\n",
    "\n",
    "    net.eval()  \n",
    "    x = im.unsqueeze(0)  \n",
    "    detections = net(x)\n",
    "    # detections、torch.Size([1, 21, 200, 5]) \n",
    "    predict_bbox = []\n",
    "    pre_dict_label_index = []\n",
    "    scores = []\n",
    "    detections = detections.cpu().detach().numpy()\n",
    "\n",
    "    find_index = np.where(detections[:, 0:, :, 0] >= dataconfidence_level)\n",
    "    detections = detections[find_index]\n",
    "    for i in range(len(find_index[1])): \n",
    "        if (find_index[1][i]) > 0: \n",
    "            sc = detections[i][0] \n",
    "            bbox = detections[i][1:] * [width, height, width, height]\n",
    "            lable_ind = find_index[1][i]-1 \n",
    "            \n",
    "            predict_bbox.append(bbox)\n",
    "            pre_dict_label_index.append(lable_ind)\n",
    "            scores.append(sc)\n",
    "\n",
    "    return rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_bbox(rgb_img, bbox, label_index, scores, label_names):\n",
    "\n",
    "    num_classes = len(label_names)  \n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, num_classes)).tolist()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(rgb_img)\n",
    "    currentAxis = plt.gca()\n",
    "\n",
    "    for i, bb in enumerate(bbox):\n",
    "\n",
    "        label_name = label_names[label_index[i]]\n",
    "        color = colors[label_index[i]]  \n",
    "\n",
    "        if scores is not None:\n",
    "            sc = scores[i]\n",
    "            display_txt = '%s: %.2f' % (label_name, sc)\n",
    "        else:\n",
    "            display_txt = '%s: ans' % (label_name)\n",
    "\n",
    "        xy = (bb[0], bb[1])\n",
    "        width = bb[2] - bb[0]\n",
    "        height = bb[3] - bb[1]\n",
    "\n",
    "        currentAxis.add_patch(plt.Rectangle(\n",
    "            xy, width, height, fill=False, edgecolor=color, linewidth=2))\n",
    "\n",
    "        currentAxis.text(xy[0], xy[1], display_txt, bbox={\n",
    "                         'facecolor': color, 'alpha': 0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSDPredictShow():\n",
    "\n",
    "    def __init__(self, img_list, dataset,  eval_categories, net=None, dataconfidence_level=0.6):\n",
    "        self.img_list = img_list\n",
    "        self.dataset = dataset\n",
    "        self.net = net\n",
    "        self.dataconfidence_level = dataconfidence_level\n",
    "        self.eval_categories = eval_categories\n",
    "\n",
    "    def show(self, img_index, predict_or_ans):\n",
    "        \n",
    "        rgb_img, true_bbox, true_label_index, predict_bbox, pre_dict_label_index, scores = ssd_predict(img_index, self.img_list,\n",
    "                                                                 self.dataset,\n",
    "                                                                 self.net,\n",
    "                                                                 self.dataconfidence_level)\n",
    "\n",
    "        if predict_or_ans == \"predict\":\n",
    "            vis_bbox(rgb_img, bbox=predict_bbox, label_index=pre_dict_label_index,\n",
    "                     scores=scores, label_names=self.eval_categories)\n",
    "\n",
    "        elif predict_or_ans == \"ans\":\n",
    "            vis_bbox(rgb_img, bbox=true_bbox, label_index=true_label_index,\n",
    "                     scores=None, label_names=self.eval_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(\n",
    "    rootpath)\n",
    "\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "color_mean = (104, 117, 123) \n",
    "input_size = 300 \n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DataTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  \n",
    "    'input_size': 300,  \n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4], \n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1], \n",
    "    'steps': [8, 16, 32, 64, 100, 300], \n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  \n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315], \n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "net = SSD(phase=\"inference\", cfg=ssd_cfg)\n",
    "net.eval()\n",
    "\n",
    "net_weights = torch.load('./weights/ssd300_50.pth',\n",
    "                         map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "#net_weights = torch.load('./weights/ssd300_mAP_77.43_v2.pth',\n",
    "#                         map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "net.load_state_dict(net_weights)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd = SSDPredictShow(img_list=train_img_list, dataset=train_dataset, eval_categories=voc_classes,\n",
    "                     net=net, dataconfidence_level=0.6)\n",
    "img_index = 0\n",
    "ssd.show(img_index, \"predict\")\n",
    "ssd.show(img_index, \"ans\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd = SSDPredictShow(img_list=val_img_list, dataset=val_dataset, eval_categories=voc_classes,\n",
    "                     net=net, dataconfidence_level=0.6)\n",
    "img_index = 0\n",
    "ssd.show(img_index, \"predict\")\n",
    "ssd.show(img_index, \"ans\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
