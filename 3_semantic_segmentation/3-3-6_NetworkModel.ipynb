{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(PSPNet, self).__init__()\n",
    "\n",
    "        block_config = [3, 4, 6, 3]  # resnet50\n",
    "        img_size = 475\n",
    "        img_size_8 = 60  \n",
    "\n",
    "        self.feature_conv = FeatureMap_convolution()\n",
    "        self.feature_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n",
    "        self.feature_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n",
    "        self.feature_dilated_res_1 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n",
    "        self.feature_dilated_res_2 = ResidualBlockPSP(\n",
    "            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n",
    "\n",
    "        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n",
    "            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n",
    "\n",
    "        self.decode_feature = DecodePSPFeature(\n",
    "            height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "        self.aux = AuxiliaryPSPlayers(\n",
    "            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_conv(x)\n",
    "        x = self.feature_res_1(x)\n",
    "        x = self.feature_res_2(x)\n",
    "        x = self.feature_dilated_res_1(x)\n",
    "\n",
    "        output_aux = self.aux(x)  \n",
    "\n",
    "        x = self.feature_dilated_res_2(x)\n",
    "\n",
    "        x = self.pyramid_pooling(x)\n",
    "        output = self.decode_feature(x)\n",
    "\n",
    "        return (output, output_aux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNormRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        outputs = self.relu(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureMap_convolution, self).__init__()\n",
    "\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n",
    "        self.cbnr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n",
    "        self.cbnr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n",
    "        self.cbnr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbnr_1(x)\n",
    "        x = self.cbnr_2(x)\n",
    "        x = self.cbnr_3(x)\n",
    "        outputs = self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(ResidualBlockPSP, self).__init__()\n",
    "\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels, mid_channels,\n",
    "                          out_channels, stride, dilation)\n",
    "        )\n",
    "\n",
    "        for i in range(n_blocks - 1):\n",
    "            self.add_module(\n",
    "                \"block\" + str(i+2),\n",
    "                bottleNeckIdentifyPSP(\n",
    "                    out_channels, mid_channels, stride, dilation)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n",
    "        super(conv2DBatchNorm, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size, stride, padding, dilation, bias=bias)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        outputs = self.batchnorm(x)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n",
    "        super(bottleNeckPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.cb_residual = conv2DBatchNorm(\n",
    "            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = self.cb_residual(x)\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, stride, dilation):\n",
    "        super(bottleNeckIdentifyPSP, self).__init__()\n",
    "\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
    "        self.cb_3 = conv2DBatchNorm(\n",
    "            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual = x\n",
    "        return self.relu(conv + residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, pool_sizes, height, width):\n",
    "        super(PyramidPooling, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        out_channels = int(in_channels / len(pool_sizes))\n",
    "\n",
    "        # pool_sizes: [6, 3, 2, 1]\n",
    "        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n",
    "        self.cbr_1 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n",
    "        self.cbr_2 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n",
    "        self.cbr_3 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n",
    "        self.cbr_4 = conv2DBatchNormRelu(\n",
    "            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.cbr_1(self.avpool_1(x))\n",
    "        out1 = F.interpolate(out1, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out2 = self.cbr_2(self.avpool_2(x))\n",
    "        out2 = F.interpolate(out2, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out3 = self.cbr_3(self.avpool_3(x))\n",
    "        out3 = F.interpolate(out3, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        out4 = self.cbr_4(self.avpool_4(x))\n",
    "        out4 = F.interpolate(out4, size=(\n",
    "            self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self, height, width, n_classes):\n",
    "        super(DecodePSPFeature, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryPSPlayers(nn.Module):\n",
    "    def __init__(self, in_channels, height, width, n_classes):\n",
    "        super(AuxiliaryPSPlayers, self).__init__()\n",
    "\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.cbr = conv2DBatchNormRelu(\n",
    "            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        self.classification = nn.Conv2d(\n",
    "            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cbr(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification(x)\n",
    "        output = F.interpolate(\n",
    "            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling(\n",
       "    (avpool_1): AdaptiveAvgPool2d(output_size=6)\n",
       "    (cbr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_2): AdaptiveAvgPool2d(output_size=3)\n",
       "    (cbr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_3): AdaptiveAvgPool2d(output_size=2)\n",
       "    (cbr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (avpool_4): AdaptiveAvgPool2d(output_size=1)\n",
       "    (cbr_4): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPlayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[ 3.8998e-01,  4.1405e-01,  4.3813e-01,  ...,  4.6911e-01,\n",
      "            4.2857e-01,  3.8803e-01],\n",
      "          [ 4.1258e-01,  4.2774e-01,  4.4290e-01,  ...,  4.2186e-01,\n",
      "            3.7417e-01,  3.2647e-01],\n",
      "          [ 4.3519e-01,  4.4143e-01,  4.4768e-01,  ...,  3.7461e-01,\n",
      "            3.1976e-01,  2.6491e-01],\n",
      "          ...,\n",
      "          [ 2.0812e-01,  1.7911e-01,  1.5011e-01,  ...,  8.0803e-02,\n",
      "            7.5976e-02,  7.1150e-02],\n",
      "          [ 2.3867e-01,  2.0303e-01,  1.6738e-01,  ...,  6.9910e-02,\n",
      "            6.3078e-02,  5.6246e-02],\n",
      "          [ 2.6923e-01,  2.2694e-01,  1.8465e-01,  ...,  5.9018e-02,\n",
      "            5.0180e-02,  4.1343e-02]],\n",
      "\n",
      "         [[-1.1691e-01, -7.7533e-02, -3.8156e-02,  ...,  2.0759e-01,\n",
      "            2.0267e-01,  1.9774e-01],\n",
      "          [-9.6929e-02, -6.5983e-02, -3.5037e-02,  ...,  1.4011e-01,\n",
      "            1.3440e-01,  1.2868e-01],\n",
      "          [-7.6948e-02, -5.4433e-02, -3.1918e-02,  ...,  7.2633e-02,\n",
      "            6.6127e-02,  5.9620e-02],\n",
      "          ...,\n",
      "          [ 5.2153e-01,  4.9294e-01,  4.6434e-01,  ...,  2.1757e-02,\n",
      "           -4.6109e-03, -3.0979e-02],\n",
      "          [ 4.9073e-01,  4.6557e-01,  4.4041e-01,  ...,  3.9791e-02,\n",
      "            2.0358e-02,  9.2502e-04],\n",
      "          [ 4.5992e-01,  4.3820e-01,  4.1647e-01,  ...,  5.7824e-02,\n",
      "            4.5327e-02,  3.2829e-02]],\n",
      "\n",
      "         [[-4.2764e-01, -4.1593e-01, -4.0422e-01,  ..., -3.3308e-01,\n",
      "           -3.1387e-01, -2.9465e-01],\n",
      "          [-3.9785e-01, -3.8722e-01, -3.7659e-01,  ..., -2.7757e-01,\n",
      "           -2.5457e-01, -2.3158e-01],\n",
      "          [-3.6806e-01, -3.5850e-01, -3.4895e-01,  ..., -2.2206e-01,\n",
      "           -1.9528e-01, -1.6850e-01],\n",
      "          ...,\n",
      "          [-3.2136e-01, -2.9435e-01, -2.6733e-01,  ..., -1.3566e-02,\n",
      "           -4.4260e-02, -7.4955e-02],\n",
      "          [-3.5914e-01, -3.2926e-01, -2.9938e-01,  ..., -3.7444e-02,\n",
      "           -7.0856e-02, -1.0427e-01],\n",
      "          [-3.9693e-01, -3.6418e-01, -3.3143e-01,  ..., -6.1323e-02,\n",
      "           -9.7452e-02, -1.3358e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7439e-01,  6.3313e-01,  5.9186e-01,  ...,  2.6715e-01,\n",
      "            3.2008e-01,  3.7300e-01],\n",
      "          [ 5.9513e-01,  5.6889e-01,  5.4264e-01,  ...,  2.6504e-01,\n",
      "            3.0639e-01,  3.4773e-01],\n",
      "          [ 5.1587e-01,  5.0465e-01,  4.9343e-01,  ...,  2.6293e-01,\n",
      "            2.9270e-01,  3.2246e-01],\n",
      "          ...,\n",
      "          [ 5.8478e-02,  7.5977e-02,  9.3476e-02,  ...,  2.0810e-01,\n",
      "            2.1066e-01,  2.1322e-01],\n",
      "          [ 4.7298e-02,  6.5640e-02,  8.3982e-02,  ...,  2.6755e-01,\n",
      "            2.6625e-01,  2.6496e-01],\n",
      "          [ 3.6118e-02,  5.5303e-02,  7.4489e-02,  ...,  3.2700e-01,\n",
      "            3.2185e-01,  3.1670e-01]],\n",
      "\n",
      "         [[-3.4040e-01, -3.4252e-01, -3.4465e-01,  ..., -6.1750e-01,\n",
      "           -6.7905e-01, -7.4059e-01],\n",
      "          [-3.3110e-01, -3.3006e-01, -3.2901e-01,  ..., -6.3364e-01,\n",
      "           -6.9548e-01, -7.5732e-01],\n",
      "          [-3.2181e-01, -3.1759e-01, -3.1338e-01,  ..., -6.4979e-01,\n",
      "           -7.1191e-01, -7.7404e-01],\n",
      "          ...,\n",
      "          [-6.5296e-02, -8.6959e-02, -1.0862e-01,  ..., -4.9946e-01,\n",
      "           -5.3496e-01, -5.7046e-01],\n",
      "          [-4.0253e-02, -6.1366e-02, -8.2479e-02,  ..., -5.3870e-01,\n",
      "           -5.7348e-01, -6.0826e-01],\n",
      "          [-1.5211e-02, -3.5773e-02, -5.6336e-02,  ..., -5.7793e-01,\n",
      "           -6.1200e-01, -6.4607e-01]],\n",
      "\n",
      "         [[ 6.4910e-01,  5.7770e-01,  5.0630e-01,  ...,  3.2111e-01,\n",
      "            3.8198e-01,  4.4286e-01],\n",
      "          [ 6.5471e-01,  5.9197e-01,  5.2923e-01,  ...,  3.2547e-01,\n",
      "            3.8074e-01,  4.3601e-01],\n",
      "          [ 6.6031e-01,  6.0623e-01,  5.5216e-01,  ...,  3.2982e-01,\n",
      "            3.7949e-01,  4.2916e-01],\n",
      "          ...,\n",
      "          [ 5.2386e-01,  4.9385e-01,  4.6384e-01,  ...,  5.4390e-02,\n",
      "            2.6313e-02, -1.7627e-03],\n",
      "          [ 5.9361e-01,  5.5820e-01,  5.2280e-01,  ...,  5.5281e-02,\n",
      "            2.2570e-02, -1.0140e-02],\n",
      "          [ 6.6336e-01,  6.2255e-01,  5.8175e-01,  ...,  5.6173e-02,\n",
      "            1.8828e-02, -1.8518e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1256e-01,  4.3190e-01,  4.5124e-01,  ...,  4.7107e-01,\n",
      "            4.4096e-01,  4.1085e-01],\n",
      "          [ 4.3558e-01,  4.4913e-01,  4.6268e-01,  ...,  4.7836e-01,\n",
      "            4.4873e-01,  4.1911e-01],\n",
      "          [ 4.5860e-01,  4.6636e-01,  4.7412e-01,  ...,  4.8564e-01,\n",
      "            4.5651e-01,  4.2737e-01],\n",
      "          ...,\n",
      "          [ 1.3078e-01,  6.9278e-02,  7.7732e-03,  ...,  6.4620e-03,\n",
      "            3.5721e-02,  6.4980e-02],\n",
      "          [ 9.6529e-02,  3.5818e-02, -2.4893e-02,  ...,  6.2949e-03,\n",
      "            3.7093e-02,  6.7892e-02],\n",
      "          [ 6.2276e-02,  2.3581e-03, -5.7559e-02,  ...,  6.1278e-03,\n",
      "            3.8466e-02,  7.0804e-02]],\n",
      "\n",
      "         [[ 2.3139e-01,  1.9009e-01,  1.4879e-01,  ..., -2.9716e-02,\n",
      "           -9.0054e-02, -1.5039e-01],\n",
      "          [ 2.4288e-01,  2.0178e-01,  1.6068e-01,  ..., -3.8624e-02,\n",
      "           -9.0793e-02, -1.4296e-01],\n",
      "          [ 2.5438e-01,  2.1348e-01,  1.7257e-01,  ..., -4.7532e-02,\n",
      "           -9.1531e-02, -1.3553e-01],\n",
      "          ...,\n",
      "          [ 4.5040e-01,  3.9275e-01,  3.3511e-01,  ...,  7.1475e-02,\n",
      "            7.0934e-02,  7.0392e-02],\n",
      "          [ 4.7244e-01,  4.1327e-01,  3.5409e-01,  ...,  3.6780e-02,\n",
      "            3.7978e-02,  3.9176e-02],\n",
      "          [ 4.9448e-01,  4.3378e-01,  3.7308e-01,  ...,  2.0848e-03,\n",
      "            5.0225e-03,  7.9603e-03]],\n",
      "\n",
      "         [[-5.8146e-01, -5.8307e-01, -5.8469e-01,  ..., -2.1751e-01,\n",
      "           -2.8999e-01, -3.6248e-01],\n",
      "          [-5.1408e-01, -5.1275e-01, -5.1142e-01,  ..., -1.7496e-01,\n",
      "           -2.3531e-01, -2.9565e-01],\n",
      "          [-4.4670e-01, -4.4243e-01, -4.3815e-01,  ..., -1.3241e-01,\n",
      "           -1.8062e-01, -2.2883e-01],\n",
      "          ...,\n",
      "          [ 3.3466e-01,  3.0299e-01,  2.7131e-01,  ..., -2.4469e-01,\n",
      "           -3.1616e-01, -3.8762e-01],\n",
      "          [ 3.0641e-01,  2.7375e-01,  2.4108e-01,  ..., -2.5720e-01,\n",
      "           -3.3711e-01, -4.1702e-01],\n",
      "          [ 2.7815e-01,  2.4451e-01,  2.1086e-01,  ..., -2.6970e-01,\n",
      "           -3.5806e-01, -4.4642e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3581e-02,  3.6748e-02,  2.9915e-02,  ...,  5.3625e-02,\n",
      "           -1.9217e-02, -9.2059e-02],\n",
      "          [ 7.4485e-02,  6.7349e-02,  6.0213e-02,  ...,  7.8579e-02,\n",
      "            2.0981e-02, -3.6618e-02],\n",
      "          [ 1.0539e-01,  9.7951e-02,  9.0511e-02,  ...,  1.0353e-01,\n",
      "            6.1178e-02,  1.8824e-02],\n",
      "          ...,\n",
      "          [ 1.6501e-01,  2.3204e-01,  2.9907e-01,  ...,  2.4601e-01,\n",
      "            1.8390e-01,  1.2179e-01],\n",
      "          [ 1.5671e-01,  2.2344e-01,  2.9018e-01,  ...,  2.4453e-01,\n",
      "            1.7139e-01,  9.8255e-02],\n",
      "          [ 1.4841e-01,  2.1485e-01,  2.8129e-01,  ...,  2.4305e-01,\n",
      "            1.5888e-01,  7.4715e-02]],\n",
      "\n",
      "         [[-5.6341e-02, -4.1127e-02, -2.5912e-02,  ..., -3.2240e-01,\n",
      "           -3.4924e-01, -3.7607e-01],\n",
      "          [-4.3118e-02, -3.2043e-02, -2.0969e-02,  ..., -3.5160e-01,\n",
      "           -3.8782e-01, -4.2404e-01],\n",
      "          [-2.9895e-02, -2.2960e-02, -1.6026e-02,  ..., -3.8079e-01,\n",
      "           -4.2640e-01, -4.7201e-01],\n",
      "          ...,\n",
      "          [ 2.8189e-02, -4.3789e-04, -2.9065e-02,  ..., -4.9601e-01,\n",
      "           -5.7323e-01, -6.5045e-01],\n",
      "          [ 6.3088e-02,  2.8264e-02, -6.5604e-03,  ..., -5.5959e-01,\n",
      "           -6.4140e-01, -7.2321e-01],\n",
      "          [ 9.7987e-02,  5.6965e-02,  1.5944e-02,  ..., -6.2317e-01,\n",
      "           -7.0957e-01, -7.9597e-01]],\n",
      "\n",
      "         [[ 4.0368e-02,  5.8241e-02,  7.6114e-02,  ...,  9.8457e-02,\n",
      "            5.1468e-02,  4.4797e-03],\n",
      "          [ 7.5153e-02,  8.7041e-02,  9.8929e-02,  ...,  9.8730e-02,\n",
      "            5.0970e-02,  3.2086e-03],\n",
      "          [ 1.0994e-01,  1.1584e-01,  1.2174e-01,  ...,  9.9004e-02,\n",
      "            5.0471e-02,  1.9374e-03],\n",
      "          ...,\n",
      "          [ 9.2083e-02,  1.3653e-01,  1.8097e-01,  ...,  1.3065e-01,\n",
      "            8.1487e-02,  3.2328e-02],\n",
      "          [ 1.4190e-01,  1.9404e-01,  2.4618e-01,  ...,  1.0490e-01,\n",
      "            5.3072e-02,  1.2465e-03],\n",
      "          [ 1.9171e-01,  2.5155e-01,  3.1139e-01,  ...,  7.9149e-02,\n",
      "            2.4657e-02, -2.9835e-02]]]], grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[-0.0237, -0.0313, -0.0388,  ..., -0.2044, -0.2492, -0.2940],\n",
      "          [-0.0574, -0.0625, -0.0676,  ..., -0.1593, -0.2016, -0.2438],\n",
      "          [-0.0912, -0.0938, -0.0964,  ..., -0.1143, -0.1539, -0.1936],\n",
      "          ...,\n",
      "          [-0.0856, -0.0681, -0.0505,  ...,  0.4196,  0.4785,  0.5374],\n",
      "          [-0.0901, -0.0774, -0.0647,  ...,  0.3996,  0.4654,  0.5313],\n",
      "          [-0.0946, -0.0868, -0.0789,  ...,  0.3796,  0.4524,  0.5251]],\n",
      "\n",
      "         [[-0.5629, -0.5429, -0.5228,  ..., -0.0990, -0.0896, -0.0801],\n",
      "          [-0.5789, -0.5524, -0.5259,  ..., -0.1177, -0.1056, -0.0936],\n",
      "          [-0.5948, -0.5619, -0.5289,  ..., -0.1365, -0.1217, -0.1070],\n",
      "          ...,\n",
      "          [-0.4079, -0.3711, -0.3344,  ..., -0.2501, -0.2759, -0.3018],\n",
      "          [-0.4400, -0.4049, -0.3697,  ..., -0.2296, -0.2416, -0.2536],\n",
      "          [-0.4722, -0.4386, -0.4050,  ..., -0.2090, -0.2072, -0.2054]],\n",
      "\n",
      "         [[ 0.4228,  0.4560,  0.4892,  ...,  0.7025,  0.7258,  0.7491],\n",
      "          [ 0.3695,  0.4104,  0.4513,  ...,  0.6959,  0.7222,  0.7486],\n",
      "          [ 0.3162,  0.3648,  0.4133,  ...,  0.6892,  0.7186,  0.7480],\n",
      "          ...,\n",
      "          [ 0.2906,  0.3148,  0.3390,  ...,  0.5566,  0.6028,  0.6491],\n",
      "          [ 0.3164,  0.3331,  0.3498,  ...,  0.5675,  0.6154,  0.6633],\n",
      "          [ 0.3423,  0.3514,  0.3605,  ...,  0.5784,  0.6280,  0.6775]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1172, -0.0936, -0.0700,  ..., -0.2061, -0.1305, -0.0549],\n",
      "          [-0.1034, -0.0826, -0.0617,  ..., -0.1678, -0.1028, -0.0378],\n",
      "          [-0.0896, -0.0715, -0.0534,  ..., -0.1296, -0.0752, -0.0207],\n",
      "          ...,\n",
      "          [-0.3378, -0.2446, -0.1515,  ..., -0.0045, -0.0169, -0.0293],\n",
      "          [-0.3083, -0.2211, -0.1339,  ..., -0.0058, -0.0166, -0.0275],\n",
      "          [-0.2788, -0.1975, -0.1162,  ..., -0.0071, -0.0164, -0.0256]],\n",
      "\n",
      "         [[ 0.3928,  0.3725,  0.3522,  ...,  0.1995,  0.2001,  0.2006],\n",
      "          [ 0.4328,  0.4067,  0.3806,  ...,  0.1792,  0.1693,  0.1595],\n",
      "          [ 0.4728,  0.4409,  0.4090,  ...,  0.1589,  0.1386,  0.1184],\n",
      "          ...,\n",
      "          [ 0.3160,  0.2791,  0.2422,  ...,  0.1257,  0.0962,  0.0666],\n",
      "          [ 0.2847,  0.2516,  0.2186,  ...,  0.1443,  0.1037,  0.0631],\n",
      "          [ 0.2534,  0.2241,  0.1949,  ...,  0.1629,  0.1113,  0.0596]],\n",
      "\n",
      "         [[-0.3114, -0.2727, -0.2340,  ..., -0.5102, -0.5211, -0.5321],\n",
      "          [-0.3195, -0.2787, -0.2378,  ..., -0.4447, -0.4557, -0.4666],\n",
      "          [-0.3276, -0.2846, -0.2416,  ..., -0.3791, -0.3902, -0.4012],\n",
      "          ...,\n",
      "          [-0.2168, -0.1874, -0.1580,  ..., -0.1715, -0.2375, -0.3035],\n",
      "          [-0.1603, -0.1397, -0.1191,  ..., -0.1178, -0.1739, -0.2300],\n",
      "          [-0.1037, -0.0919, -0.0801,  ..., -0.0642, -0.1103, -0.1564]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3143,  0.3137,  0.3132,  ..., -0.0041, -0.0191, -0.0342],\n",
      "          [ 0.2637,  0.2630,  0.2623,  ...,  0.0116, -0.0074, -0.0265],\n",
      "          [ 0.2132,  0.2123,  0.2114,  ...,  0.0274,  0.0043, -0.0188],\n",
      "          ...,\n",
      "          [-0.0137,  0.0213,  0.0563,  ...,  0.5465,  0.5529,  0.5593],\n",
      "          [-0.0014,  0.0313,  0.0639,  ...,  0.5712,  0.5711,  0.5709],\n",
      "          [ 0.0110,  0.0413,  0.0716,  ...,  0.5960,  0.5893,  0.5825]],\n",
      "\n",
      "         [[-0.4642, -0.4579, -0.4517,  ..., -0.4724, -0.4833, -0.4942],\n",
      "          [-0.4437, -0.4347, -0.4257,  ..., -0.4519, -0.4609, -0.4699],\n",
      "          [-0.4233, -0.4115, -0.3998,  ..., -0.4315, -0.4385, -0.4455],\n",
      "          ...,\n",
      "          [-0.3264, -0.2625, -0.1986,  ..., -0.1270, -0.1817, -0.2364],\n",
      "          [-0.3485, -0.2759, -0.2034,  ..., -0.0747, -0.1256, -0.1765],\n",
      "          [-0.3706, -0.2894, -0.2082,  ..., -0.0224, -0.0695, -0.1166]],\n",
      "\n",
      "         [[ 0.1383,  0.1471,  0.1559,  ...,  0.4582,  0.4711,  0.4840],\n",
      "          [ 0.1531,  0.1670,  0.1808,  ...,  0.4868,  0.5012,  0.5155],\n",
      "          [ 0.1680,  0.1868,  0.2057,  ...,  0.5155,  0.5313,  0.5471],\n",
      "          ...,\n",
      "          [ 0.6912,  0.6826,  0.6741,  ...,  0.6890,  0.6816,  0.6742],\n",
      "          [ 0.6823,  0.6708,  0.6593,  ...,  0.6757,  0.6637,  0.6517],\n",
      "          [ 0.6734,  0.6589,  0.6445,  ...,  0.6624,  0.6458,  0.6293]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1192,  0.0949,  0.0706,  ...,  0.1450,  0.1614,  0.1777],\n",
      "          [ 0.0887,  0.0698,  0.0510,  ...,  0.1323,  0.1514,  0.1705],\n",
      "          [ 0.0582,  0.0448,  0.0314,  ...,  0.1196,  0.1415,  0.1634],\n",
      "          ...,\n",
      "          [ 0.1903,  0.1944,  0.1986,  ...,  0.3436,  0.3632,  0.3827],\n",
      "          [ 0.2071,  0.2123,  0.2174,  ...,  0.3811,  0.3971,  0.4130],\n",
      "          [ 0.2238,  0.2301,  0.2363,  ...,  0.4186,  0.4310,  0.4433]],\n",
      "\n",
      "         [[ 0.0430,  0.0516,  0.0601,  ...,  0.0668,  0.1179,  0.1691],\n",
      "          [ 0.0778,  0.0765,  0.0751,  ...,  0.0880,  0.1266,  0.1652],\n",
      "          [ 0.1127,  0.1014,  0.0901,  ...,  0.1092,  0.1352,  0.1612],\n",
      "          ...,\n",
      "          [ 0.1731,  0.1191,  0.0652,  ...,  0.0426,  0.0404,  0.0382],\n",
      "          [ 0.1479,  0.1016,  0.0553,  ...,  0.0090,  0.0077,  0.0063],\n",
      "          [ 0.1227,  0.0841,  0.0455,  ..., -0.0246, -0.0251, -0.0255]],\n",
      "\n",
      "         [[-0.3594, -0.3226, -0.2857,  ..., -0.5153, -0.5630, -0.6106],\n",
      "          [-0.3579, -0.3222, -0.2865,  ..., -0.4802, -0.5200, -0.5599],\n",
      "          [-0.3564, -0.3218, -0.2872,  ..., -0.4451, -0.4771, -0.5091],\n",
      "          ...,\n",
      "          [-0.0128, -0.0336, -0.0544,  ...,  0.0169, -0.0457, -0.1083],\n",
      "          [-0.0331, -0.0551, -0.0772,  ...,  0.0171, -0.0511, -0.1192],\n",
      "          [-0.0533, -0.0766, -0.0999,  ...,  0.0173, -0.0564, -0.1302]]]],\n",
      "       grad_fn=<UpsampleBilinear2DBackward1>))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "dummy_img = torch.rand(batch_size, 3, 475, 475)\n",
    "\n",
    "outputs = net(dummy_img)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
